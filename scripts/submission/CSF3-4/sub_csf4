#!/bin/python3.6
import os
import sys
import argparse

# create parser for parsing input file name
parser = argparse.ArgumentParser(description='Create Gaussian slurm runscript')
parser.add_argument("-i", "--input", help="Input file name", required=True, type=str)
parser.add_argument("-n", "--nodes", help="Number of nodes. multicore=1, multinode>1, serial=0; default=1", default=1, type=int)
parser.add_argument("-c", "--cores", help="Number of cores. Between 2-40; default=8", type=int, default=8)
args = parser.parse_args()

if args.nodes > 1: 
    cores_queue = "multinode"
else:
    cores_queue = "multicore"

if args.cores > 40 and args.nodes < 2:
    print("Number of cores must be between 2 and 40")
    sys.exit()
elif args.nodes == 0 or args.cores == 1:
    cores_queue = "serial"

# check if number of cores is the same as in input file
#def check_cores(input_file, cores):
#    with open(input_file, "r") as f:
#        lines = f.readlines()
#        for line in lines:
#            if "nprocs" in line:
#                if int(line.split()[2]) != cores:
#                    print("Number of cores in input file does not match number of cores specified")
#                    ask user if they want to change number of cores in input file
#                    change_cores = input("Do you want to change the number of cores in the input file? (y/n)")
#                    if change_cores == "y":
#                        with open(input_file, "w") as f:
#                            for line in lines:
#                                if "nproc" in line:
#                                    line = f"%pal   nprocs {cores}\n"
#                                f.write(line)
#                    else:
#
#                         sys.exit()
    
# Check for program(s)
program = ""
with open(args.input, "r") as f:
    lines = f.readlines()
    for line in lines:
         if "nbo7" in line.lower():
            program = "nbo7"
            break

# create slurm runscript (g16)
if args.input[-4:] == ".com" and program == "":
    def create_runscript(cores_queue, cores, input_file):
        script = f"""#!/bin/bash --login
#SBATCH -p {cores_queue}      # (or --partition) Single-node multicore
#SBATCH --ntasks {cores}             # (or --ntasks=) Number of cores (2--40)
#SBATCH --job-name {input_file.split(".")[0]}     # Short name for the job

# Load g16 for the CPU type our job is running on
module load gaussian/g16c01_em64t_detectcpu

## Set up scratch dir (please do this!)
export GAUSS_SCRDIR=/scratch/$USER/gau_temp_$SLURM_JOB_ID
mkdir -p $GAUSS_SCRDIR

## Say how much memory to use (4GB per core)
export GAUSS_MDEF=$((SLURM_NTASKS*4))GB

## Inform Gaussian how many cores to use
export GAUSS_PDEF=$SLURM_NTASKS

$g16root/g16/g16 < $SLURM_JOB_NAME.com > $SLURM_JOB_NAME.log
rm -rf $GAUSS_SCRDIR"""
        return script

# create slurm runscript (g16)
elif args.input[-4:] == ".com" and program == "nbo7":
    def create_runscript(cores_queue, cores, input_file):
        script = f"""#!/bin/bash --login
#SBATCH -p {cores_queue}      # (or --partition) Single-node multicore
#SBATCH --ntasks {cores}             # (or --ntasks=) Number of cores (2--40)
#SBATCH --job-name {input_file.split(".")[0]}     # Short name for the job

# Load g16 for the CPU type our job is running on
module load gaussian/g16c01_em64t_detectcpu

# Load NBO 7.0.8
module load nbo/7.0.8-i8

## Set up scratch dir (please do this!)
export GAUSS_SCRDIR=/scratch/$USER/gau_temp_$SLURM_JOB_ID
mkdir -p $GAUSS_SCRDIR

## Say how much memory to use (4GB per core)
export GAUSS_MDEF=$((SLURM_NTASKS*4))GB

## Inform Gaussian how many cores to use
export GAUSS_PDEF=$SLURM_NTASKS

$g16root/g16/g16 < $SLURM_JOB_NAME.com > $SLURM_JOB_NAME.log
rm -rf $GAUSS_SCRDIR"""
        return script

# create slurm runscript (orca)
elif args.input[-4:] == ".inp":
    def create_runscript(cores_queue, cores, input_file):
        script = f"""#!/bin/bash --login
#SBATCH -p {cores_queue}       # (or --partition=) Parallel job using cores on a single node
#SBATCH -n {cores}                # (or --ntasks=) Number of cores (2--40)
#SBATCH --job-name {input_file.split(".")[0]}""" + """
###########################
job=${SLURM_JOB_NAME}

job=$(echo ${job%%.*})
##########################

# Load the modulefile in a clean environment
module purge
module load orca/5.0.4-gompi-2021a
export RSH_COMMAND=ssh
##########################
export scratchlocation=/scratch

if [ ! -d $scratchlocation/$USER ]

then

  mkdir -p $scratchlocation/$USER

fi
##########################
tdir=$(mktemp -d $scratchlocation/$USER/orcajob_$SLURM_JOB_ID-XXXX)

# Copy only the necessary stuff in submit directory to scratch directory. Add more here if needed.

cp  $SLURM_SUBMIT_DIR/*.inp $tdir/

cp  $SLURM_SUBMIT_DIR/*.gbw $tdir/

cp  $SLURM_SUBMIT_DIR/*.xyz $tdir/
#########################

# Creating nodefile in scratch

# echo $SLURM_NODELIST > $tdir/$job.nodes

# cd to scratch

cd $tdir

# Copy job and node info to beginning of outputfile

echo "Job execution start: $(date)" >>  $SLURM_SUBMIT_DIR/$job.out

echo "Shared library path: $LD_LIBRARY_PATH" >>  $SLURM_SUBMIT_DIR/$job.out

echo "Slurm Job ID is: ${SLURM_JOB_ID}" >>  $SLURM_SUBMIT_DIR/$job.out

echo "Slurm Job name is: ${SLURM_JOB_NAME}" >>  $SLURM_SUBMIT_DIR/$job.out

echo $SLURM_NODELIST >> $SLURM_SUBMIT_DIR/$job.out

#Start ORCA job. ORCA is started using full pathname (necessary for parallel execution). Output file is written directly to submit directory on frontnode.

$(which orca) $job.inp >  $SLURM_SUBMIT_DIR/$job.out

# ORCA has finished here. Now copy important stuff back (xyz files, GBW files etc.). Add more here if needed.

cp $tdir/*.gbw $SLURM_SUBMIT_DIR

cp $tdir/*.engrad $SLURM_SUBMIT_DIR

cp $tdir/*.xyz $SLURM_SUBMIT_DIR

cp $tdir/*.loc $SLURM_SUBMIT_DIR

cp $tdir/*.qro $SLURM_SUBMIT_DIR

cp $tdir/*.uno $SLURM_SUBMIT_DIR

cp $tdir/*.unso $SLURM_SUBMIT_DIR

cp $tdir/*.uco $SLURM_SUBMIT_DIR

cp $tdir/*.hess $SLURM_SUBMIT_DIR

cp $tdir/*.cis $SLURM_SUBMIT_DIR

cp $tdir/*.dat $SLURM_SUBMIT_DIR

cp $tdir/*.mp2nat $SLURM_SUBMIT_DIR

cp $tdir/*.nat $SLURM_SUBMIT_DIR

cp $tdir/*.scfp_fod $SLURM_SUBMIT_DIR

cp $tdir/*.scfp $SLURM_SUBMIT_DIR

cp $tdir/*.scfr $SLURM_SUBMIT_DIR

cp $tdir/*.nbo $SLURM_SUBMIT_DIR

cp $tdir/FILE.47 $SLURM_SUBMIT_DIR

cp $tdir/*_property.txt $SLURM_SUBMIT_DIR

cp $tdir/*spin* $SLURM_SUBMIT_DIR"""
        return script
        
# check if input file exists
if not os.path.isfile(args.input):
    print("Input file does not exist")
    sys.exit()
# check input file format
elif args.input[-4:] != ".com" and args.input[-4:] != ".inp":
    print("Input file must be of .com (g16) or .inp (orca) format")
    sys.exit()
# if input file exists, create slurm runscript and adjust number of cores
else:
    # check if number of cores in input file matches number of cores specified
    with open("run.sh", "w") as f:
        f.write(create_runscript(cores_queue, args.cores, args.input))
    os.system(f"sbatch run.sh {args.input}")
# Runs alias for jobs_csf4.sh to update the jobs list
os.system("jobs_csf4.sh")
